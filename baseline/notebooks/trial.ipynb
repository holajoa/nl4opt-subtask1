{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.utils import parse_args, get_reader, load_model, get_out_filename, get_tagset\n",
    "from pytorch_lightning import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parser():\n",
    "    import argparse\n",
    "    p = argparse.ArgumentParser(description='Model configuration.', add_help=False)\n",
    "    p.add_argument('--train', type=str, help='Path to the train data.', default=None)\n",
    "    p.add_argument('--test', type=str, help='Path to the test data.', default=None)\n",
    "    p.add_argument('--dev', type=str, help='Path to the dev data.', default=None)\n",
    "\n",
    "    p.add_argument('--out_dir', type=str, help='Output directory.', default='.')\n",
    "    p.add_argument('--iob_tagging', type=str, help='IOB tagging scheme', default='conll')\n",
    "\n",
    "    p.add_argument('--max_instances', type=int, help='Maximum number of instances', default=1500)\n",
    "    p.add_argument('--max_length', type=int, help='Maximum number of tokens per instance.', default=100)\n",
    "\n",
    "    p.add_argument('--encoder_model', type=str, help='Pretrained encoder model to use', default='xlm-roberta-large')\n",
    "    p.add_argument('--model', type=str, help='Model path.', default=None)\n",
    "    p.add_argument('--model_name', type=str, help='Model name.', default=None)\n",
    "    p.add_argument('--stage', type=str, help='Training stage', default='fit')\n",
    "    p.add_argument('--prefix', type=str, help='Prefix for storing evaluation files.', default='test')\n",
    "\n",
    "    p.add_argument('--batch_size', type=int, help='Batch size.', default=128)\n",
    "    p.add_argument('--accum_grad_batches', type=int, help='Number of batches for accumulating gradients.', default=1)\n",
    "    p.add_argument('--gpus', type=int, help='Number of GPUs.', default=1)\n",
    "    p.add_argument('--cuda', type=str, help='Cuda Device', default='cuda:0')\n",
    "    p.add_argument('--epochs', type=int, help='Number of epochs for training.', default=5)\n",
    "    p.add_argument('--lr', type=float, help='Learning rate', default=1e-5)\n",
    "    p.add_argument('--dropout', type=float, help='Dropout rate', default=0.1)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = build_parser()\n",
    "sg = parser.parse_args([\n",
    "    \"--test\", \"../../data/dev/dev.txt\", \n",
    "    \"--out_dir\", \"../trained_model\", \n",
    "    \"--model_name\", \"roberta_squad2_final\", \n",
    "    \"--gpus\", \"1\", \n",
    "    \"--encoder_model\", \"deepset/roberta-base-squad2\", \n",
    "    \"--batch_size\", \"32\", \n",
    "    \"--model\", \"../trained_model/roberta_squad2_lr_2e-5/lightning_logs/version_0\", \n",
    "    \"--max_length\", \"200\", \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [--train TRAIN] [--test TEST] [--dev DEV]\n",
      "                             [--out_dir OUT_DIR] [--iob_tagging IOB_TAGGING]\n",
      "                             [--max_instances MAX_INSTANCES]\n",
      "                             [--max_length MAX_LENGTH]\n",
      "                             [--encoder_model ENCODER_MODEL] [--model MODEL]\n",
      "                             [--model_name MODEL_NAME] [--stage STAGE]\n",
      "                             [--prefix PREFIX] [--batch_size BATCH_SIZE]\n",
      "                             [--accum_grad_batches ACCUM_GRAD_BATCHES]\n",
      "                             [--gpus GPUS] [--cuda CUDA] [--epochs EPOCHS]\n",
      "                             [--lr LR] [--dropout DROPOUT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"31c8f7f2-b83b-49f6-974f-dec5b7130a85\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=c:\\Users\\holaj\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-36072GqO86kEWuPHV.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "timestamp = time.time()\n",
    "sg = parse_args()\n",
    "out_dir_path = sg.out_dir + '/' + sg.model_name\n",
    "\n",
    "# load the dataset first\n",
    "test_data = get_reader(\n",
    "    file_path=sg.test, \n",
    "    target_vocab=get_tagset(sg.iob_tagging), \n",
    "    max_instances=sg.max_instances, \n",
    "    max_length=sg.max_length, \n",
    "    encoder_model=sg.encoder_model, \n",
    ")\n",
    "\n",
    "model, model_file = load_model(\n",
    "    sg.model, \n",
    "    tag_to_id=get_tagset(sg.iob_tagging), \n",
    ")\n",
    "model = model.to(sg.cuda)\n",
    "# use pytorch lightnings saver here.\n",
    "eval_file = get_out_filename(sg.out_dir, model_file, prefix=sg.prefix, output_tags=True)\n",
    "\n",
    "out_str = ''\n",
    "test_dataloaders = DataLoader(\n",
    "    test_data, batch_size=sg.batch_size, \n",
    "    collate_fn=model.collate_batch, \n",
    "    shuffle=False, \n",
    "    drop_last=False, \n",
    ")\n",
    "index = 0\n",
    "for batch in tqdm(test_dataloaders, total=len(test_dataloaders)):\n",
    "    pred_tags = model.predict_tags(batch, device=sg.cuda)\n",
    "\n",
    "    for pred_tag_inst in pred_tags:\n",
    "        out_str += '\\n'.join(pred_tag_inst)\n",
    "        out_str += '\\n\\n\\n'\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 19:14:36 - INFO - reader - Reading file ../../data/dev/dev.txt\n",
      "2022-09-23 19:14:37 - INFO - reader - Finished reading 99 instances from file ../../data/dev/dev.txt\n"
     ]
    }
   ],
   "source": [
    "dev_reader = get_reader(\n",
    "    file_path='../../data/dev/dev.txt', \n",
    "    max_length=200, \n",
    "    target_vocab=get_tagset('conll'), \n",
    "    encoder_model=sg.encoder_model, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11759</th>\n",
       "      <td>B-VAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11760</th>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11761</th>\n",
       "      <td>B-VAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11762</th>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11763</th>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11764 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           O\n",
       "0          O\n",
       "1          O\n",
       "2          O\n",
       "3          O\n",
       "4          O\n",
       "...      ...\n",
       "11759  B-VAR\n",
       "11760      O\n",
       "11761  B-VAR\n",
       "11762      O\n",
       "11763      O\n",
       "\n",
       "[11764 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../trained_model/test_base_roberta_squad2_lr_2e-5_timestamp_1663584495.1579309_final_full_output.tsv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nl4opt-holajoa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84a35194ff216313c76cfc2da7143b81382f9a7e4b02afa172ae3ab9d741be5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
